{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Defining_Methods.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPnb3dhvl5hua9IIS3l72Ys"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"tU6D2SGmBEaT","colab_type":"text"},"source":["#Imports"]},{"cell_type":"code","metadata":{"id":"6Xun5t8CtO3i","colab_type":"code","colab":{}},"source":["import os, os.path\n","from subprocess import getoutput\n","import tensorflow as tf\n","from tensorflow import keras as ks\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import confusion_matrix\n","from skimage.transform import resize\n","import cv2\n","#Data visualization\n","import seaborn as sns\n","from matplotlib import pyplot as plt\n","\n","import glob\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","import time\n","import math\n","\n","from collections import Counter\n","\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers import Bidirectional\n","from tensorflow.keras.layers import LSTM\n","from tensorflow.keras.layers import CuDNNLSTM\n","from tensorflow.keras.layers import ConvLSTM2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Softmax"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ciI3c5ArBGkM","colab_type":"text"},"source":["#Import dei dataset, cropped o interpolated"]},{"cell_type":"markdown","metadata":{"id":"8CQi_F8pBPh4","colab_type":"text"},"source":["##Import database cropped"]},{"cell_type":"code","metadata":{"id":"XCZeH16oZbdb","colab_type":"code","colab":{}},"source":["def get_dataset_crop(db, _batch_size, _dim1, _dim2, drive):\n","\n","  if db == '9k':\n","    #%cd /content\n","    os.chdir(\"/content\")\n","    downloaded = drive.CreateFile({'id':\"1nderD97u_2d1I6TE3ey8wBtEWqLAosk4\"})\n","    downloaded.GetContentFile('data_9400_88.zip')\n","    #!rm -rf DB_Repo\n","    getoutput(\"rm -rf DB_Repo\")\n","    #!unzip -q data_9400_88.zip -d DB_Repo/\n","    getoutput(\"unzip -q data_9400_88.zip -d DB_Repo/\")\n","\n","  elif db == '14k':\n","    #%cd /content\n","    os.chdir(\"/content\")\n","    downloaded = drive.CreateFile({'id':\"1z5J7XE_KJYzZGJd-NHX8PUggED2ZK8HG\"})\n","    downloaded.GetContentFile('data.zip')\n","    #!rm -rf DB_Repo\n","    getoutput(\"rm -rf DB_Repo\")\n","    #!unzip -q data.zip -d DB_Repo/\n","    getoutput(\"unzip -q data.zip -d DB_Repo/\")\n","\n","  elif db == '18k':\n","    #%cd /content\n","    os.chdir(\"/content\")\n","    downloaded = drive.CreateFile({'id':\"18ESID3MpwG-SzZPE1EENzsGPh8vl8ti9\"})\n","    downloaded.GetContentFile('data_18800.zip')\n","    #!rm -rf DB_Repo\n","    getoutput(\"rm -rf DB_Repo\")\n","    #!unzip -q data_18800.zip -d DB_Repo/\n","    getoutput(\"unzip -q data_18800.zip -d DB_Repo/\")\n","\n","  else:\n","    raise ValueError(\"Keyword for database not recognized; use '9k', '14k' or '18k'.\")\n","  \n","  path, dirs, files = next(os.walk(\"/content/DB_Repo/data\"))\n","  file_count = len(files)\n","  print(file_count)\n","  #%cd /content/DB_Repo/data\n","  os.chdir(\"/content/DB_Repo/data\")\n","\n","  ##PARAMETERS\n","\n","  dim1 = _dim1\n","  dim2 = _dim2\n","\n","  total_pixels = dim1 * dim2\n","  MAX_LEN = 64 #fisso\n","\n","  #Considero il primo 20% della lista di dati come test set\n","  test_percentage = 20 #%\n","  #Considero il 20% della lista di dati - esclusi i dati di test - come validation set\n","  validation_percentage = 20 #%\n","\n","  #COSTANTI E DICHIARAZIONI\n","\n","  database_list = list()\n","  labels_list = list()\n","  obf_list = list()\n","\n","  #LETTURA E RESIZE IMMAGINI\n","\n","  print(\"START IMAGE INPUT\")\n","  #Aggiungo i valori alle liste leggendo i vari files\n","  for filename in glob.glob('*.npy'):\n","    temp_img = np.load(filename)\n","    temp_img = temp_img.reshape((-1, MAX_LEN)).astype(np.uint16)\n","    #flattening\n","    temp_img = temp_img.flatten()\n","    dimensione = temp_img.size\n","\n","    #padding fino alla dimensione dim1xdim2\n","    #o crop fino a dim1xdim2 pixels\n","    if dimensione < total_pixels:\n","      temp_img = np.pad(temp_img, (0, total_pixels - dimensione), mode='constant',constant_values=0)\n","    elif dimensione >= total_pixels:\n","      temp_img = temp_img[0:total_pixels]\n","    else:\n","      raise ValueError(\"Error in reading images.\")\n","\n","    temp_img = temp_img.reshape((dim1, dim2))\n","    database_list.append(temp_img)\n","    #Salvo la label, ossia la classe\n","    labels_list.append(extract_label(filename))\n","    #Salvo la lista di offuscatori di ogni file\n","    obf_list.append(extract_obf(filename))\n","  print(\"END IMAGE INPUT\")\n","\n","  #SHUFFLE\n","\n","  #Ho i valori e le etichette in due liste (+ obf); \n","  #le mescolo mantenendo l'ordine tra valore-label\n","  temp = list(zip(database_list, labels_list, obf_list))\n","  np.random.shuffle(temp)\n","  database_list, labels_list, obf_list = zip(*temp)\n","\n","  #SUDDIVISIONE DATI\n","  #Suddivido in training set, test set e validation test\n","  assert len(database_list) == len(labels_list) == len(obf_list)\n","  #print(len(database_list))\n","\n","  #Split per creare test set\n","  index_to_split = math.ceil((len(database_list) * test_percentage) / 100)\n","  indices = [(0, index_to_split - 1), (index_to_split, len(database_list) - 1)]\n","\n","  test_list, training_list = [database_list[s:e+1] for s,e in indices]\n","  labels_test_list, labels_training_list = [labels_list[s:e+1] for s,e in indices]\n","  obf_test_list, obf_training_list = [obf_list[s:e+1] for s,e in indices]\n","\n","  #Split per creare validation set\n","  index_to_split = math.ceil((len(training_list) * validation_percentage) / 100)\n","  indices = [(0, index_to_split - 1), (index_to_split, len(training_list) - 1)]\n","\n","  validation_list, training_list = [training_list[s:e+1] for s,e in indices]\n","  labels_validation_list, labels_training_list = [labels_training_list[s:e+1] for s,e in indices]\n","  obf_validation_list, obf_training_list = [obf_training_list[s:e+1] for s,e in indices]\n","\n","  #Trasformo i valori in numpy.ndarray\n","  train_images = np.array(training_list)\n","  test_images = np.array(test_list)\n","  validation_images = np.array(validation_list)\n","\n","  train_labels = np.array(labels_training_list)\n","  test_labels = np.array(labels_test_list)\n","  validation_labels = np.array(labels_validation_list)\n","\n","  train_obf = np.array(obf_training_list)\n","  test_obf = np.array(obf_test_list)\n","  validation_obf = np.array(obf_validation_list)\n","\n","  #Encoding delle labels;\n","  #Se nella suddivisione il 100% di una classe è fuori dal train_labels,\n","  #Vi sarà un errore nell'encoding delle labels negli altri set.\n","  label_encoder = LabelEncoder()\n","  label_encoder.fit(train_labels)\n","  train_labels_encoded = label_encoder.transform(train_labels)\n","  test_labels_encoded = label_encoder.transform(test_labels)\n","  validation_labels_encoded = label_encoder.transform(validation_labels)\n","\n","  #Normalizzazione valori in range 0-1\n","  train_images = train_images / 65535.0\n","  test_images = test_images / 65535.0\n","  validation_images = validation_images / 65535.0\n","\n","  #Dichiarazione altri parametri\n","  n_classes = len(list(label_encoder.classes_))\n","\n","  sets_and_labels = (train_images, train_labels_encoded, test_images, test_labels_encoded, validation_images, validation_labels_encoded)\n","  numpy_arrays = (train_obf, test_obf, validation_obf)\n","  return sets_and_labels, numpy_arrays, label_encoder, n_classes"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vp_G7y96BLeZ","colab_type":"text"},"source":["##Import database interpolato"]},{"cell_type":"code","metadata":{"id":"6S7A085N7aiF","colab_type":"code","colab":{}},"source":["#NB: cv2 inverts rows and cols wrt numpy\n","def get_dataset_interp(db, _batch_size, _dim1, _dim2, drive):\n","\n","  if db == '9k':\n","    #%cd /content\n","    os.chdir(\"/content\")\n","    downloaded = drive.CreateFile({'id':\"1nderD97u_2d1I6TE3ey8wBtEWqLAosk4\"})\n","    downloaded.GetContentFile('data_9400_88.zip')\n","    #!rm -rf DB_Repo\n","    getoutput(\"rm -rf DB_Repo\")\n","    #!unzip -q data_9400_88.zip -d DB_Repo/\n","    getoutput(\"unzip -q data_9400_88.zip -d DB_Repo/\")\n","\n","  elif db == '14k':\n","    #%cd /content\n","    os.chdir(\"/content\")\n","    downloaded = drive.CreateFile({'id':\"1z5J7XE_KJYzZGJd-NHX8PUggED2ZK8HG\"})\n","    downloaded.GetContentFile('data.zip')\n","    #!rm -rf DB_Repo\n","    getoutput(\"rm -rf DB_Repo\")\n","    #!unzip -q data.zip -d DB_Repo/\n","    getoutput(\"unzip -q data.zip -d DB_Repo/\")\n","\n","  elif db == '18k':\n","    #%cd /content\n","    os.chdir(\"/content\")\n","    downloaded = drive.CreateFile({'id':\"18ESID3MpwG-SzZPE1EENzsGPh8vl8ti9\"})\n","    downloaded.GetContentFile('data_18800.zip')\n","    #!rm -rf DB_Repo\n","    getoutput(\"rm -rf DB_Repo\")\n","    #!unzip -q data_18800.zip -d DB_Repo/\n","    getoutput(\"unzip -q data_18800.zip -d DB_Repo/\")\n","\n","  else:\n","    raise ValueError(\"Keyword for database not recognized; use '9k', '14k' or '18k'.\")\n","  \n","  path, dirs, files = next(os.walk(\"/content/DB_Repo/data\"))\n","  file_count = len(files)\n","  print(file_count)\n","  #%cd /content/DB_Repo/data\n","  os.chdir(\"/content/DB_Repo/data\")\n","\n","  ##PARAMETERS\n","\n","  dim1 = _dim1\n","  dim2 = _dim2\n","\n","  #total_pixels = dim1 * dim2\n","  MAX_LEN = 64 #fisso\n","\n","  #Considero il primo 20% della lista di dati come test set\n","  test_percentage = 20 #%\n","  #Considero il 20% della lista di dati - esclusi i dati di test - come validation set\n","  validation_percentage = 20 #%\n","\n","  #COSTANTI E DICHIARAZIONI\n","\n","  database_list = list()\n","  labels_list = list()\n","  obf_list = list()\n","\n","  #LETTURA E RESIZE IMMAGINI\n","\n","  print(\"START IMAGE INPUT\")\n","  #Aggiungo i valori alle liste leggendo i vari files\n","  for filename in glob.glob('*.npy'):\n","    temp_img = np.load(filename)\n","    temp_img = temp_img.reshape((-1, MAX_LEN)).astype('float32') \n","    temp_img = cv2.resize(temp_img, (dim2, dim1), interpolation=cv2.INTER_CUBIC)\n","    database_list.append(temp_img)\n","    #Salvo la label, ossia la classe\n","    labels_list.append(extract_label(filename))\n","    #Salvo la lista di offuscatori di ogni file\n","    obf_list.append(extract_obf(filename))\n","  print(\"END IMAGE INPUT\")\n","\n","  #SHUFFLE\n","\n","  #Ho i valori e le etichette in due liste (+ obf); \n","  #le mescolo mantenendo l'ordine tra valore-label\n","  temp = list(zip(database_list, labels_list, obf_list))\n","  np.random.shuffle(temp)\n","  database_list, labels_list, obf_list = zip(*temp)\n","\n","  #SUDDIVISIONE DATI\n","  #Suddivido in training set, test set e validation test\n","  assert len(database_list) == len(labels_list) == len(obf_list)\n","  #print(len(database_list))\n","\n","  #Split per creare test set\n","  index_to_split = math.ceil((len(database_list) * test_percentage) / 100)\n","  indices = [(0, index_to_split - 1), (index_to_split, len(database_list) - 1)]\n","\n","  test_list, training_list = [database_list[s:e+1] for s,e in indices]\n","  labels_test_list, labels_training_list = [labels_list[s:e+1] for s,e in indices]\n","  obf_test_list, obf_training_list = [obf_list[s:e+1] for s,e in indices]\n","\n","  #Split per creare validation set\n","  index_to_split = math.ceil((len(training_list) * validation_percentage) / 100)\n","  indices = [(0, index_to_split - 1), (index_to_split, len(training_list) - 1)]\n","\n","  validation_list, training_list = [training_list[s:e+1] for s,e in indices]\n","  labels_validation_list, labels_training_list = [labels_training_list[s:e+1] for s,e in indices]\n","  obf_validation_list, obf_training_list = [obf_training_list[s:e+1] for s,e in indices]\n","\n","  #Trasformo i valori in numpy.ndarray\n","  train_images = np.array(training_list)\n","  test_images = np.array(test_list)\n","  validation_images = np.array(validation_list)\n","\n","  train_labels = np.array(labels_training_list)\n","  test_labels = np.array(labels_test_list)\n","  validation_labels = np.array(labels_validation_list)\n","\n","  train_obf = np.array(obf_training_list)\n","  test_obf = np.array(obf_test_list)\n","  validation_obf = np.array(obf_validation_list)\n","\n","  #Encoding delle labels;\n","  #Se nella suddivisione il 100% di una classe è fuori dal train_labels,\n","  #Vi sarà un errore nell'encoding delle labels negli altri set.\n","  label_encoder = LabelEncoder()\n","  label_encoder.fit(train_labels)\n","  train_labels_encoded = label_encoder.transform(train_labels)\n","  test_labels_encoded = label_encoder.transform(test_labels)\n","  validation_labels_encoded = label_encoder.transform(validation_labels)\n","\n","  #Normalizzazione valori in range 0-1\n","  train_images = train_images / 65535.0\n","  test_images = test_images / 65535.0\n","  validation_images = validation_images / 65535.0\n","\n","  #Dichiarazione altri parametri\n","  n_classes = len(list(label_encoder.classes_))\n","\n","  sets_and_labels = (train_images, train_labels_encoded, test_images, test_labels_encoded, validation_images, validation_labels_encoded)\n","  numpy_arrays = (train_obf, test_obf, validation_obf)\n","  return sets_and_labels, numpy_arrays, label_encoder, n_classes"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E2j4sCPQBS07","colab_type":"text"},"source":["#Definizione metodi per plotting"]},{"cell_type":"code","metadata":{"id":"kAnuPwSotTKU","colab_type":"code","colab":{}},"source":["#Extract the class from the file name, if the class is the string before che -\n","def extract_label(from_string):\n","  position = from_string.index('-') # gets position of the - in the filename\n","  substring = from_string[0:position]\n","  return substring\n","\n","def extract_obf(from_string):\n","  start_pos = from_string.index('-')\n","  end_pos = from_string.index('.')\n","  substring = from_string[(start_pos + 1):end_pos]\n","  return substring\n","\n","def mapping_labels_encoded(label_encoder):\n","  for index in range(len(list(label_encoder.classes_))):\n","    print(index, end = \"-> \")\n","    print(list(label_encoder.inverse_transform([index]))) \n","\n","class TimeHistory(ks.callbacks.Callback):\n","    def on_train_begin(self, logs={}):\n","        self.times = []\n","\n","    def on_epoch_begin(self, epoch, logs={}):\n","        self.epoch_time_start = time.time()\n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        self.times.append(time.time() - self.epoch_time_start)\n","\n","def plot_image(i, predictions_array, true_label, img):\n","  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n","  plt.grid(False)\n","  plt.xticks([])\n","  plt.yticks([])\n","\n","  plt.imshow(img, cmap=plt.cm.binary)\n","\n","  predicted_label = np.argmax(predictions_array)\n","  if predicted_label == true_label:\n","    color = 'blue'\n","  else:\n","    color = 'red'\n","\n","  plt.xlabel(\"{} {:2.0f}% ({})\".format(predicted_label,\n","                                100*np.max(predictions_array),\n","                                true_label),\n","                                color=color)\n","\n","def plot_value_array(i, predictions_array, true_label):\n","  predictions_array, true_label = predictions_array, true_label[i]\n","  plt.grid(False)\n","  plt.xticks(range(10))\n","  plt.yticks([])\n","  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n","  plt.ylim([0, 1])\n","  predicted_label = np.argmax(predictions_array)\n","\n","  thisplot[predicted_label].set_color('red')\n","  thisplot[true_label].set_color('blue')\n","\n","def plot_model_acc(hist):\n","  fig = plt.figure()\n","  #Plot training & validation accuracy values\n","  plt.plot(hist.history['acc'])\n","  plt.plot(hist.history['val_acc'])\n","  plt.title('Model accuracy')\n","  plt.ylabel('Accuracy')\n","  plt.xlabel('Epoch')\n","  plt.legend(['Train', 'Test'], loc='upper left')\n","  return fig\n","  #plt.show()\n","\n","def plot_model_loss(hist):\n","  fig = plt.figure()\n","  #Plot training & validation accuracy values\n","  plt.plot(hist.history['loss'])\n","  plt.plot(hist.history['val_loss'])\n","  plt.title('Model loss')\n","  plt.ylabel('Loss')\n","  plt.xlabel('Epoch')\n","  plt.legend(['Train', 'Test'], loc='upper left')\n","  return fig\n","  #plt.show()\n","\n","def plot_conf_matrix(modelLSTM, validation_images, validation_labels_encoded, label_encoder):\n","  #Necessito di un array con tutte le labels\n","  validation_predictions = modelLSTM.predict_classes(validation_images)\n","\n","  conf_matr = confusion_matrix(y_true = validation_labels_encoded, y_pred = validation_predictions)\n","  #print(conf_matr)\n","\n","  con_mat_norm = np.around(conf_matr.astype('float') / conf_matr.sum(axis=1)[:, np.newaxis], decimals=2)\n","\n","  con_mat_df = pd.DataFrame(con_mat_norm,\n","                          index = list(label_encoder.classes_), \n","                          columns = list(label_encoder.classes_))\n","\n","  figure = plt.figure(figsize=(len(list(label_encoder.classes_)), len(list(label_encoder.classes_))), dpi=50)\n","  sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n","  plt.tight_layout()\n","  plt.ylabel('True label')\n","  plt.xlabel('Predicted label')\n","  return figure \n","  #plt.show()\n","\n","def stampa_grafo_orizzontale(dict_errori, grandezza_x, grandezza_y, x_label, y_label, colore):\n","  fig = plt.figure(figsize=(grandezza_x, grandezza_y))\n","\n","  plt.bar(list(dict_errori.keys()), list(dict_errori.values()), color=colore)\n","\n","  plt.axhline(np.asarray(list(dict_errori.values())).mean(), color=\"red\") # Horizontal line adding the threshold\n","  #plt.axhline(np.asarray(list(dict_errori.values())).std(), color=\"grey\") # Horizontal line adding the threshold\n","  plt.axhline(np.asarray(list(dict_errori.values())).max(), color=\"black\") # Horizontal line adding the threshold\n","\n","  plt.xlabel(x_label) # x label\n","  plt.ylabel(y_label) # y label\n","  return fig\n","  #plt.show()\n","\n","def stampa_grafo_verticale(dict_errori, grandezza_x, grandezza_y, x_label, y_label, colore):\n","  fig = plt.figure(figsize=(grandezza_x, grandezza_y))\n","\n","  plt.barh(list(dict_errori.keys()), list(dict_errori.values()), color=colore)\n","\n","  plt.axvline(np.asarray(list(dict_errori.values())).mean(), color=\"red\") # Horizontal line adding the threshold\n","  #plt.axvline(np.asarray(list(dict_errori.values())).std(), color=\"grey\") # Horizontal line adding the threshold\n","  plt.axvline(np.asarray(list(dict_errori.values())).max(), color=\"black\") # Horizontal line adding the threshold\n","\n","  plt.xlabel(x_label) # x label\n","  plt.ylabel(y_label) # y label\n","  return fig\n","  #plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C4BXXYDb395I","colab_type":"code","colab":{}},"source":["def computing_incorrects_stats(modelLSTM, validation_images, validation_labels_encoded, validation_obf, label_encoder):\n","  incorrects = np.nonzero(modelLSTM.predict_classes(validation_images) != validation_labels_encoded)\n","\n","  temp_incorrects = list()\n","  for elem in incorrects[0]:\n","    temp_incorrects.append(elem)\n","  incorrects = temp_incorrects\n","\n","  wrong_labels_str = list()\n","  wrong_obf = list()\n","  for elem in incorrects:\n","    string_to_append = str(label_encoder.inverse_transform([validation_labels_encoded[elem]]))\n","    wrong_labels_str.append(string_to_append)\n","    wrong_obf.append(validation_obf[elem])\n","  \n","  assert len(wrong_labels_str) == len(wrong_obf)\n","\n","  set_obfs = list()\n","  for elem in wrong_obf:\n","    temp_list = elem.split('-')  \n","    temp_list.sort()\n","    separator = '-'\n","    temp_list = separator.join(temp_list)\n","    set_obfs.append(temp_list)\n","\n","  single_obf = list()\n","  for elem in wrong_obf:\n","    temp_list = elem.split('-')\n","    for sub_elem in temp_list:\n","      single_obf.append(sub_elem)\n","\n","  single_obfs_total = list()\n","\n","  for elem in validation_obf:\n","    temp_list = elem.split('-')\n","\n","    for sub_elem in temp_list:\n","      single_obfs_total.append(sub_elem)\n","\n","\n","  count_labels_err = Counter(wrong_labels_str)\n","  count_obf_err = Counter(wrong_obf)\n","  count_set_obfs = Counter(set_obfs)\n","\n","  count_single_obfs_total = Counter(single_obfs_total)\n","  count_single_obf = Counter(single_obf)\n","\n","  single_obf_percentage = dict()\n","\n","  for key, value in count_single_obfs_total.items():\n","    error_val = count_single_obf.get(key)\n","    if type(error_val)==None.__class__:\n","      percentuale = 0\n","    else:\n","      percentuale = (100 * error_val) / value\n","    single_obf_percentage.update({key : percentuale})\n","\n","  return count_labels_err, count_obf_err, count_set_obfs, single_obf_percentage"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1mKA7f-BBYOI","colab_type":"text"},"source":["#Definizione modelli"]},{"cell_type":"markdown","metadata":{"id":"GisOI3RRuere","colab_type":"text"},"source":["##Definizione modello Vanilla"]},{"cell_type":"code","metadata":{"id":"k5r1_MFhugXf","colab_type":"code","colab":{}},"source":["def modelVanilla(num_units1, num_units2, _batch_size, n_classes, _patience, sub_db, n_epochs):\n","\n","  (train_images, train_labels_encoded, test_images, test_labels_encoded) = sub_db\n","\n","  modelLSTM = ks.Sequential()\n","\n","  #Batch size should be (at most) the same number of hidden cells\n","  #no activation selection\n","\n","  modelLSTM.add(Flatten())\n","  modelLSTM.add(tf.keras.layers.Dense(num_units1))\n","  modelLSTM.add(tf.keras.layers.Dense(num_units2))\n","  modelLSTM.add(Dense(n_classes, activation='softmax'))\n","\n","  modelLSTM.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","  #Definizione callback\n","  es = ks.callbacks.EarlyStopping(monitor='val_loss', patience=_patience,\n","                                  mode='auto', restore_best_weights=True, verbose=0)\n","  time_callback = TimeHistory()\n","\n","  #Validation_data è usato al termine di ogni epoch;\n","  hist = modelLSTM.fit(train_images, train_labels_encoded, \n","                      batch_size = _batch_size,\n","                      validation_data=(test_images, test_labels_encoded), \n","                      epochs=n_epochs, shuffle='true',\n","                      callbacks=[time_callback, es], verbose=0)\n","\n","  return modelLSTM, hist, time_callback"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zk0IaR7RBZV-","colab_type":"text"},"source":["##Definizione modello LSTM"]},{"cell_type":"code","metadata":{"id":"ZBNFuu7q8ulo","colab_type":"code","colab":{}},"source":["def modelLSTM(num_units1, num_units2, time_steps, n_features, _batch_size, n_classes, _patience, sub_db, n_epochs):\n","\n","  (train_images, train_labels_encoded, test_images, test_labels_encoded) = sub_db\n","\n","  modelLSTM = ks.Sequential()\n","\n","  #Batch size should be (at most) the same number of hidden cells\n","  #no activation selection\n","  modelLSTM.add(Bidirectional(CuDNNLSTM(num_units1, unit_forget_bias='true', return_sequences='true'),\n","                              input_shape=(time_steps, n_features)))\n","  modelLSTM.add(Bidirectional(CuDNNLSTM(num_units2, unit_forget_bias='true')))\n","  modelLSTM.add(Dense(n_classes, activation='softmax'))\n","\n","  modelLSTM.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","  #Definizione callback\n","  es = ks.callbacks.EarlyStopping(monitor='val_loss', patience=_patience,\n","                                  mode='auto', restore_best_weights=True, verbose=0)\n","  time_callback = TimeHistory()\n","\n","  #Validation_data è usato al termine di ogni epoch;\n","  hist = modelLSTM.fit(train_images, train_labels_encoded, \n","                      batch_size = _batch_size,\n","                      validation_data=(test_images, test_labels_encoded), \n","                      epochs=n_epochs, shuffle='true',\n","                      callbacks=[time_callback, es], verbose=0)\n","\n","  return modelLSTM, hist, time_callback"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1WYGYn9hN9Ar","colab_type":"text"},"source":["##Definizione modello ConvLSTM2D\n","\n","Per questo modello c'è bisogno di un ulteriore reshape."]},{"cell_type":"code","metadata":{"id":"EQffzp75N8k3","colab_type":"code","colab":{}},"source":["def reshape_for_ConvLSTM2D(sub_db, time_steps, n_features, _channels):\n","\n","  (train_images, test_images, validation_images) = sub_db\n","\n","  channels = _channels\n","  #Reshape degli array di immagini\n","  n_img, _, _ = train_images.shape\n","  n_img2, _, _ = test_images.shape\n","  n_img3, _, _ = validation_images.shape\n","\n","  train_images = train_images.reshape(n_img, -1, time_steps, n_features, channels)\n","  test_images = test_images.reshape(n_img2, -1, time_steps, n_features, channels)\n","  validation_images = validation_images.reshape(n_img3, -1, time_steps, n_features, channels)\n","\n","  _, n_ts_blocks, _, _, _ = train_images.shape\n","  \n","  return train_images, test_images, validation_images, n_ts_blocks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KuEBgTRkOZUd","colab_type":"code","colab":{}},"source":["def modelConvLSTM2D(num_units1, time_steps, n_features, n_ts_blocks, _batch_size, channels, n_classes, _patience, sub_db, n_epochs):\n","\n","  (train_images, train_labels_encoded, test_images, test_labels_encoded) = sub_db\n","\n","  modelLSTM = ks.Sequential()\n","\n","  #Batch size should be (at most) the same number of hidden cells\n","  #no activation selection\n","  modelLSTM.add(Bidirectional(ConvLSTM2D(num_units1, (3, 3),\n","                              padding='same', unit_forget_bias='true', activation='relu'), \n","                              input_shape=(n_ts_blocks, time_steps, n_features, channels)))\n","  modelLSTM.add(Flatten())\n","  modelLSTM.add(Dense(n_classes, activation='softmax'))\n","\n","  modelLSTM.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","  #Definizione callback\n","  es = ks.callbacks.EarlyStopping(monitor='val_loss', patience=_patience,\n","                                  mode='auto', restore_best_weights=True, verbose=0)\n","  time_callback = TimeHistory()\n","\n","  #Validation_data è usato al termine di ogni epoch;\n","  hist = modelLSTM.fit(train_images, train_labels_encoded, \n","                      batch_size = _batch_size,\n","                      validation_data=(test_images, test_labels_encoded), \n","                      epochs=n_epochs, shuffle='true',\n","                      callbacks=[time_callback, es], verbose=0)\n","  \n","  return modelLSTM, hist, time_callback"],"execution_count":null,"outputs":[]}]}