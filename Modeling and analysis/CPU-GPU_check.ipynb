{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CPU-GPU_check.ipynb","provenance":[],"authorship_tag":"ABX9TyMOov2p/zdbktbi0bLulh8g"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"0wdc_pPp5TpT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594225437506,"user_tz":-120,"elapsed":3309,"user":{"displayName":"Pleasant94","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc18QmWcekRk39ps1vtP2fsFwmCWuEr7kJj8SPVg=s64","userId":"00661494034163855202"}},"outputId":"5413bf2b-cb65-4fda-9e17-c7debef0f55b"},"source":["!lscpu |grep 'Model name'"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Model name:          Intel(R) Xeon(R) CPU @ 2.30GHz\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YaDvPBP86Bar","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594225440458,"user_tz":-120,"elapsed":6239,"user":{"displayName":"Pleasant94","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc18QmWcekRk39ps1vtP2fsFwmCWuEr7kJj8SPVg=s64","userId":"00661494034163855202"}},"outputId":"98686a74-1ee8-49a1-c8f6-8eb76261d272"},"source":["#memory that we can use\n","!free -h --si | awk  '/Mem:/{print $2}'"],"execution_count":2,"outputs":[{"output_type":"stream","text":["13G\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Xi_IFokR6Ci_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1594225442747,"user_tz":-120,"elapsed":8513,"user":{"displayName":"Pleasant94","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc18QmWcekRk39ps1vtP2fsFwmCWuEr7kJj8SPVg=s64","userId":"00661494034163855202"}},"outputId":"2b2933e2-e6fb-4b7b-b945-38474cc90043"},"source":["#hard disk space that we can use\n","!df -h / | awk '{print $4}'"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Avail\n","34G\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"euEI7nzF5wMj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594225445849,"user_tz":-120,"elapsed":11600,"user":{"displayName":"Pleasant94","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc18QmWcekRk39ps1vtP2fsFwmCWuEr7kJj8SPVg=s64","userId":"00661494034163855202"}},"outputId":"bab48557-2e93-4baa-db13-14849b188981"},"source":["#GPU count and name\n","!nvidia-smi -L"],"execution_count":4,"outputs":[{"output_type":"stream","text":["GPU 0: Tesla K80 (UUID: GPU-b8564f8b-ed75-e817-bde9-799bec1620a1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5YyrNN4i5xHa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":384},"executionInfo":{"status":"ok","timestamp":1594225448651,"user_tz":-120,"elapsed":14389,"user":{"displayName":"Pleasant94","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc18QmWcekRk39ps1vtP2fsFwmCWuEr7kJj8SPVg=s64","userId":"00661494034163855202"}},"outputId":"a476fbd5-cf17-418a-fa01-6bbdf5e893bf"},"source":["#use this command to see GPU activity while doing Deep Learning tasks, for this command 'nvidia-smi' and for above one to work, go to 'Runtime > change runtime type > Hardware Accelerator > GPU'\n","!nvidia-smi"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Wed Jul  8 16:24:07 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g-Fqznnz4SC-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1594225457283,"user_tz":-120,"elapsed":23006,"user":{"displayName":"Pleasant94","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc18QmWcekRk39ps1vtP2fsFwmCWuEr7kJj8SPVg=s64","userId":"00661494034163855202"}},"outputId":"8fe6d2a2-5104-4e9e-a579-1dc140d4d31a"},"source":["import tensorflow as tf\n","tf.test.gpu_device_name()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"9eKDWBx24WYh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":256},"executionInfo":{"status":"ok","timestamp":1594225472931,"user_tz":-120,"elapsed":38640,"user":{"displayName":"Pleasant94","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc18QmWcekRk39ps1vtP2fsFwmCWuEr7kJj8SPVg=s64","userId":"00661494034163855202"}},"outputId":"4ffa3e89-90b4-4801-db98-a5faec5bee49"},"source":["# memory footprint support libraries/code\n","!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil\n","!pip install psutil\n","!pip install humanize\n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isnâ€™t guaranteed\n","gpu = GPUs[0]\n","def printm():\n"," process = psutil.Process(os.getpid())\n"," print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n"," print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","printm() "],"execution_count":7,"outputs":[{"output_type":"stream","text":["Collecting gputil\n","  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n","Building wheels for collected packages: gputil\n","  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=776e8c4db846a42571c0e8f99e6f173a8327fc74ed1e1bdf5f80e86e698aeb7d\n","  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n","Successfully built gputil\n","Installing collected packages: gputil\n","Successfully installed gputil-1.4.0\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n","Gen RAM Free: 12.3 GB  | Proc size: 936.9 MB\n","GPU RAM Free: 11311MB | Used: 130MB | Util   1% | Total 11441MB\n"],"name":"stdout"}]}]}